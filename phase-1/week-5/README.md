## ğŸ§  Vision Module â€“ AI Rover Project

 - Owner: Sabera Banu
- Phase: Vision System (Weeks 4â€“5)
- Platform: OAK-D / DepthAI / Jetson

## ğŸ“– Overview

This module handles the visual perception of the AI Rover.
It captures frames from the OAK-D camera, performs YOLO-based object detection, and estimates depth for navigation.
It supports both:

### âœ… Real Hardware Mode â€“ OAK-D camera

#### ğŸ§© Simulation Mode â€“ Webcam or dummy data

#### âš™ï¸ Implemented Features
## Week 4 â€“ Vision Foundation

Initialized DepthAI camera pipeline (RGB + depth).

### Implemented:

- get_latest_frame() â€“ Capture RGB frame

- get_center_depth() â€“ Get central depth distance

- Added simulation mode (dummy or webcam input).

## Week 5 â€“ YOLO Integration

- Integrated YOLO Spatial Detection Network.

- Added get_detections_with_depth() for object + depth output.

- Created test scripts for camera, depth, and detection validation.

### ğŸ§© VisionSystem Class
#### class VisionSystem:
    - def get_latest_frame()
    - def get_center_depth()
    - def get_detections_with_depth()


#### Example simulated output:

- [YOLO] person (91%) at X=70mm, Y=63mm, Z=2184mm
- Center depth: 1.57 m

### ğŸ§ª Testing
**Script	Purpose**
- test_camera.py	Tests frame capture
- test_depth.py	Tests depth reading
- test_yolo.py	Tests object detection
- test_integration.py	Combined system test

**Run test:**

- python3 -m test.test_camera

## ğŸ“… Progress Summary
Week	Task	Status
Week 4	Vision system setup	âœ…
Week 5	YOLO detection integration	âœ…
Week 6	Hardware testing (Jetson + OAK-D)	ğŸ”„ Upcoming
## ğŸ”® Next Steps

- Test on real hardware (OAK-D).

- Fine-tune YOLO for specific objects.

- Begin integration with motor and audio modules.